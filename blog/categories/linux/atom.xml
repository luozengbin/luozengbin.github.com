<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux | Akira's Tech Notes]]></title>
  <link href="http://luozengbin.github.io/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://luozengbin.github.io/"/>
  <updated>2015-05-16T00:22:09+09:00</updated>
  <id>http://luozengbin.github.io/</id>
  <author>
    <name><![CDATA[luozengbin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[メモ]VirtualBox HostOnly on Linux]]></title>
    <link href="http://luozengbin.github.io/blog/2015-02-06-%5B%E3%83%A1%E3%83%A2%5Dvirtualbox-hostonly-on-linux.html"/>
    <updated>2015-02-06T00:00:00+09:00</updated>
    <id>http://luozengbin.github.io/blog/[メモ]virtualbox-hostonly-on-linux</id>
    <content type="html"><![CDATA[<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. VirtualBox使用出来るネットワークアダプタ</a></li>
<li><a href="#sec-2">2. 複数アダプターユースケース</a></li>
<li><a href="#sec-3">3. ホストオンリーネットワークの追加手順</a>
<ul>
<li><a href="#sec-3-1">3.1. カーネルモジュールのロード</a></li>
<li><a href="#sec-3-2">3.2. ホストオンリーネットワークの追加</a></li>
<li><a href="#sec-3-3">3.3. アダプターと紐付ける</a></li>
</ul>
</li>
<li><a href="#sec-4">4. 参考</a></li>
</ul>
</div>
</div>


<p>
VirtualBox上で動く仮想マシンにデフォルトではNATネットワークアダプタが割り当てられてい
るため、Host OSとの通信ができないです。これを回避するために <code>ホストオンリーネットワー
ク</code> アダプターを使えば回避できる。最近のバージョン追加手順が変わったため、メモしてお
きます。
</p>




<p>
<!-- more -->
</p>




<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> VirtualBox使用出来るネットワークアダプタ</h2>
<div class="outline-text-2" id="text-1">
<ol class="org-ol">
<li>NAT
VirtualBox のデフォルト設定。ゲスト OS からインターネットは繋がる。
ゲスト OS とホストOS 間は繋がらない。
</li>
<li>ブリッジネットワーク
ゲスト OS のネットワークがホスト OS と同じネットワークに繋がる。イン
ターネットに繋がり、ゲスト OS とホスト OS の間が繋がる。同じネットワー
ク上の他の PC からも見える。
</li>
<li>内部ネットワーク
仮想マシンを複数起動したときに、各マシン間を繋ぐためのネットワーク？
</li>
<li>ホストオンリーネットワーク
ホスト OS と ゲスト OS 間のネットワーク。ゲスト OS をローカルのウェ
ブサービス開発環境として利用する場合、次のようなネットワークだと都合
が良いです。
</li>
</ol>
</div>
</div>




<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> 複数アダプターユースケース</h2>
<div class="outline-text-2" id="text-2">
<p>
アダプタ ２ に「ホストオンリーネットワーク」を割り当て、アダプ
タ １に「NAT」を割り当てます。こうすると、ホスト OS とゲスト OS 間が繋
がり、NAT によりゲスト OS から外部ネットへのアクセスもきるようになります。
</p>
</div>
</div>




<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> ホストオンリーネットワークの追加手順</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1"><span class="section-number-3">3.1</span> カーネルモジュールのロード</h3>
<div class="outline-text-3" id="text-3-1">
<pre class="example">
sudo modprobe vboxdrv
sudo modprobe vboxnetadp
sudo modprobe vboxnetflt
</pre>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2"><span class="section-number-3">3.2</span> ホストオンリーネットワークの追加</h3>
<div class="outline-text-3" id="text-3-2">
<p>
ホストと通信するための仮想ブリッジを追加するイメージとなります。またこのブリッジに対
してIPの指定やDHCPサーバ機能の有効化も可能です。VirtualBoxのグローバル設定ダイアログか
らホストオンリーネットワークを追加する。
</p>

<ul class="org-ul">
<li>ホストオンリーネットワークの追加
<img src="img/2015-02-06-vbox001.png" alt="2015-02-06-vbox001.png" />
</li>

<li>ブリッジにIPを割り当てる
<img src="img/2015-02-06-vbox002.png" alt="2015-02-06-vbox002.png" />
</li>

<li>DHCPサーバを有効化する
<img src="img/2015-02-06-vbox003.png" alt="2015-02-06-vbox003.png" />
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-3-3" class="outline-3">
<h3 id="sec-3-3"><span class="section-number-3">3.3</span> アダプターと紐付ける</h3>
<div class="outline-text-3" id="text-3-3">
<p>
仮想マシンのネットワークディバイス設定でアダプター２を有効化し、作成したホストオンリー
ネットワークと紐付ける。
  <img src="img/2015-02-06-vbox004.png" alt="2015-02-06-vbox004.png" />
</p>

<p>
仮想マシンを機能すると共に仮想ブリッジディバイスがホストOS上で自動的に生成されること
を確認する。
</p>

<pre class="example">
$ ifconfig
★省略..........

vboxnet0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 192.168.56.1  netmask 255.255.255.0  broadcast 192.168.56.255
        inet6 fe80::800:27ff:fe00:0  prefixlen 64  scopeid 0x20&lt;link&gt;
        ether 0a:00:27:00:00:00  txqueuelen 1000  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 107  bytes 18000 (17.5 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</pre>
</div>
</div>
</div>




<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> 参考</h2>
<div class="outline-text-2" id="text-4">
<ul class="org-ul">
<li><a href="https://wiki.archlinux.org/index.php/VirtualBox#Load_the_VirtualBox_kernel_modules">Load the VirtualBox kernel modules</a>
</li>
</ul>
</div>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[メモ]自宅サーバディスク増設記録]]></title>
    <link href="http://luozengbin.github.io/blog/2014-11-16-%5B%E3%83%A1%E3%83%A2%5D%E8%87%AA%E5%AE%85%E3%82%B5%E3%83%BC%E3%83%90%E3%83%87%E3%82%A3%E3%82%B9%E3%82%AF%E5%A2%97%E8%A8%AD%E8%A8%98%E9%8C%B2.html"/>
    <updated>2014-11-16T00:00:00+09:00</updated>
    <id>http://luozengbin.github.io/blog/[メモ]自宅サーバディスク増設記録</id>
    <content type="html"><![CDATA[<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. 環境</a></li>
<li><a href="#sec-2">2. ツールの整備</a></li>
<li><a href="#sec-3">3. ディスク情報確認</a></li>
<li><a href="#sec-4">4. 現在のパーティション構成</a></li>
<li><a href="#sec-5">5. 増設後のパーティション構成</a></li>
<li><a href="#sec-6">6. 増設手順</a>
<ul>
<li><a href="#sec-6-1">6.1. gdiskでパーティションを初期化する</a></li>
<li><a href="#sec-6-2">6.2. LVMパーティション再構成</a></li>
<li><a href="#sec-6-3">6.3. 増設結果を確認する</a></li>
</ul>
</li>
<li><a href="#sec-7">7. 参考情報</a></li>
</ul>
</div>
</div>


<p>
半年前、約1年ちょっと使った <a href="http://www.wdc.com/global/products/specs/?driveID=1092&language=6">WD Blue(WD10EZEX)</a> ディスクが壊れた (I/Oスピードが激遅い現
象が起きた)ため、RMA保証手続きで交換しました。交換で約1ヶ月かかる、かつサーバがRAID0構
成のため、代用品を購入し、復旧を実施した。RAM交換で届いたディスクがずっと置いたまま、
今日もう一台のNASサーバに増設を実施します。
</p>




<p>
<!-- more -->
</p>




<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> 環境</h2>
<div class="outline-text-2" id="text-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">OS</td>
<td class="left">CentOS Linux release 7.0.1406 (Core)</td>
</tr>

<tr>
<td class="left">/dev/sda</td>
<td class="left"><a href="http://www.crucial.com/usa/en/storage-ssd-mx100-ja">Crucial MX100 2.5インチ内蔵型SSD 256GB SATAIII</a></td>
</tr>

<tr>
<td class="left">/dev/sdb</td>
<td class="left">増設HDD: WD10EZEX [1TB SATA600 7200]</td>
</tr>
</tbody>
</table>
</div>
</div>




<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> ツールの整備</h2>
<div class="outline-text-2" id="text-2">
<p>
<code>hdparm</code> は HDD (SATA/IDE)デバイスのパフォーマンスとベンチマークのツールです｡
</p>
<pre class="example">
$ sudo yum install hdparm
</pre>

<p>
<code>sdparm</code> SCSIデバイスのパフォーマンスとベンチマークのツールです｡
</p>
<pre class="example">
$ sudo yum install sdparm
</pre>

<p>
GPTをサポートするパーティションリングツール
</p>
<pre class="example">
$ sudo yum install gdisk
</pre>
</div>
</div>




<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> ディスク情報確認</h2>
<div class="outline-text-2" id="text-3">
<p>
<code>/dev/sda</code> SSDのハード情報を確認する。
</p>
<pre class="example">
$ sudo hdparm -I /dev/sda

/dev/sda:

ATA device, with non-removable media
    Model Number:       Crucial_CT256MX100SSD1
    Serial Number:      ************
    Firmware Revision:  *****
    Transport:          Serial, ATA8-AST, SATA 1.0a, SATA II Extensions, SATA Rev 2.5, SATA Rev 2.6, SATA Rev 3.0
Standards:
    Used: unknown (minor revision code 0x0028)
    Supported: 9 8 7 6 5 
    Likely used: 9
Configuration:
    Logical     max current
    cylinders   16383   16383
    heads       16  16
    sectors/track   63  63
    --
    CHS current addressable sectors:   16514064
    LBA    user addressable sectors:  268435455
    LBA48  user addressable sectors:  500118192
    Logical  Sector size:                   512 bytes
    Physical Sector size:                  4096 bytes
    Logical Sector-0 offset:                  0 bytes
    device size with M = 1024*1024:      244198 MBytes
    device size with M = 1000*1000:      256060 MBytes (256 GB)
    cache/buffer size  = unknown
    Form Factor: 2.5 inch
    Nominal Media Rotation Rate: Solid State Device
Capabilities:
    LBA, IORDY(can be disabled)
    Queue depth: 32
    Standby timer values: spec'd by Standard, with device specific minimum
    R/W multiple sector transfer: Max = 16  Current = 16
    Advanced power management level: 254
    DMA: mdma0 mdma1 mdma2 udma0 udma1 udma2 udma3 udma4 udma5 *udma6 
         Cycle time: min=120ns recommended=120ns
    PIO: pio0 pio1 pio2 pio3 pio4 
         Cycle time: no flow control=120ns  IORDY flow control=120ns
Commands/features:
    Enabled Supported:
       *    SMART feature set
            Security Mode feature set
       *    Power Management feature set
       *    Write cache
       *    Look-ahead
       *    Host Protected Area feature set
       *    WRITE_BUFFER command
       *    READ_BUFFER command
       *    NOP cmd
       *    DOWNLOAD_MICROCODE
       *    Advanced Power Management feature set
            SET_MAX security extension
       *    48-bit Address feature set
       *    Device Configuration Overlay feature set
       *    Mandatory FLUSH_CACHE
       *    FLUSH_CACHE_EXT
       *    SMART error logging
       *    SMART self-test
       *    General Purpose Logging feature set
       *    WRITE_{DMA|MULTIPLE}_FUA_EXT
       *    64-bit World wide name
       *    IDLE_IMMEDIATE with UNLOAD
            Write-Read-Verify feature set
       *    WRITE_UNCORRECTABLE_EXT command
       *    {READ,WRITE}_DMA_EXT_GPL commands
       *    Segmented DOWNLOAD_MICROCODE
       *    Gen1 signaling speed (1.5Gb/s)
       *    Gen2 signaling speed (3.0Gb/s)
       *    Gen3 signaling speed (6.0Gb/s)
       *    Native Command Queueing (NCQ)
       *    Phy event counters
       *    NCQ priority information
       *    unknown 76[15]
       *    DMA Setup Auto-Activate optimization
            Device-initiated interface power management
            Asynchronous notification (eg. media change)
       *    Software settings preservation
            unknown 78[8]
       *    SMART Command Transport (SCT) feature set
       *    SCT Write Same (AC2)
       *    SCT Features Control (AC4)
       *    SCT Data Tables (AC5)
       *    reserved 69[4]
       *    reserved 69[7]
       *    Data Set Management TRIM supported (limit 8 blocks)
       *    Deterministic read ZEROs after TRIM
Security: 
    Master password revision code = 65534
        supported
    not enabled
    not locked
        frozen
    not expired: security count
        supported: enhanced erase
    2min for SECURITY ERASE UNIT. 2min for ENHANCED SECURITY ERASE UNIT.
Logical Unit WWN Device Identifier: ***************
    NAA     : 5
    IEEE OUI    : 00a075
    Unique ID   : ********
Checksum: correct
</pre>

<p>
<code>/dev/sdb</code> HDDのハード情報を確認する。
</p>
<pre class="example">
$ sudo hdparm -I /dev/sdb

/dev/sdb:

ATA device, with non-removable media
    Model Number:       WDC WD10EZEX-00RKKA0
    Serial Number:      WD-WMC**********
    Firmware Revision:  80.00A80
    Transport:          Serial, SATA 1.0a, SATA II Extensions, SATA Rev 2.5, SATA Rev 2.6, SATA Rev 3.0
Standards:
    Supported: 8 7 6 5 
    Likely used: 8
Configuration:
    Logical     max current
    cylinders   16383   16383
    heads       16  16
    sectors/track   63  63
    --
    CHS current addressable sectors:   16514064
    LBA    user addressable sectors:  268435455
    LBA48  user addressable sectors: 1953525168
    Logical  Sector size:                   512 bytes
    Physical Sector size:                  4096 bytes
    device size with M = 1024*1024:      953869 MBytes
    device size with M = 1000*1000:     1000204 MBytes (1000 GB)
    cache/buffer size  = unknown
Capabilities:
    LBA, IORDY(can be disabled)
    Queue depth: 32
    Standby timer values: spec'd by Standard, with device specific minimum
    R/W multiple sector transfer: Max = 16  Current = 16
    DMA: mdma0 mdma1 mdma2 udma0 udma1 udma2 udma3 udma4 udma5 *udma6 
         Cycle time: min=120ns recommended=120ns
    PIO: pio0 pio1 pio2 pio3 pio4 
         Cycle time: no flow control=120ns  IORDY flow control=120ns
Commands/features:
    Enabled Supported:
       *    SMART feature set
            Security Mode feature set
       *    Power Management feature set
       *    Write cache
       *    Look-ahead
       *    Host Protected Area feature set
       *    WRITE_BUFFER command
       *    READ_BUFFER command
       *    NOP cmd
       *    DOWNLOAD_MICROCODE
            Power-Up In Standby feature set
       *    SET_FEATURES required to spinup after power up
            SET_MAX security extension
       *    48-bit Address feature set
       *    Device Configuration Overlay feature set
       *    Mandatory FLUSH_CACHE
       *    FLUSH_CACHE_EXT
       *    SMART error logging
       *    SMART self-test
       *    General Purpose Logging feature set
       *    64-bit World wide name
       *    {READ,WRITE}_DMA_EXT_GPL commands
       *    Segmented DOWNLOAD_MICROCODE
       *    Gen1 signaling speed (1.5Gb/s)
       *    Gen2 signaling speed (3.0Gb/s)
       *    Gen3 signaling speed (6.0Gb/s)
       *    Native Command Queueing (NCQ)
       *    Host-initiated interface power management
       *    Phy event counters
       *    NCQ priority information
       *    unknown 76[15]
       *    DMA Setup Auto-Activate optimization
       *    Software settings preservation
       *    SMART Command Transport (SCT) feature set
       *    SCT Write Same (AC2)
       *    SCT Features Control (AC4)
       *    SCT Data Tables (AC5)
            unknown 206[7]
            unknown 206[12] (vendor specific)
            unknown 206[13] (vendor specific)
Security: 
    Master password revision code = 65534
        supported
    not enabled
    not locked
        frozen
    not expired: security count
        supported: enhanced erase
    112min for SECURITY ERASE UNIT. 112min for ENHANCED SECURITY ERASE UNIT. 
Logical Unit WWN Device Identifier: ****************
    NAA     : 5
    IEEE OUI    : 0014ee
    Unique ID   : ******
Checksum: correct
$
</pre>
</div>
</div>




<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> 現在のパーティション構成</h2>
<div class="outline-text-2" id="text-4">
<p>
<code>/dev/sda</code> の物理パーティション構成を確認する。
</p>
<pre class="example">
$ sudo gdisk -l /dev/sda 
GPT fdisk (gdisk) version 0.8.6

Partition table scan:
  MBR: protective
  BSD: not present
  APM: not present
  GPT: present

Found valid GPT with protective MBR; using GPT.
Disk /dev/sda: 500118192 sectors, 238.5 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): A2BE7525-7A02-4E36-8C41-B9E4487690BD
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 500118158
Partitions will be aligned on 2048-sector boundaries
Total free space is 2669 sectors (1.3 MiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048          411647   200.0 MiB   EF00  EFI System Partition
   2          411648         1435647   500.0 MiB   0700  
   3         1435648       500117503   237.8 GiB   8E00  
$
</pre>

<p>
LVMの構成状況
</p>
<pre class="example">
$ sudo lvmdiskscan
  /dev/centos/swap [       7.27 GiB] 
  /dev/sda1        [     200.00 MiB] 
  /dev/centos/root [      50.00 GiB] 
  /dev/sda2        [     500.00 MiB] 
  /dev/centos/home [     180.52 GiB] 
........
</pre>

<p>
先頭の物理パーティションをブート関係用にマウントしています。
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />

<col  class="left" />

<col  class="left" />
</colgroup>
<tbody>
<tr>
<td class="left">/dev/sda1</td>
<td class="left">vfat</td>
<td class="left">/boot/efi</td>
<td class="left">200MB</td>
</tr>

<tr>
<td class="left">/dev/sda2</td>
<td class="left">xfs</td>
<td class="left">/boot</td>
<td class="left">500MB</td>
</tr>
</tbody>
</table>

<p>
三番目の物理パーティションをLVMで割って使っています。
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />

<col  class="left" />

<col  class="left" />

<col  class="left" />

<col  class="left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="left">PV</th>
<th scope="col" class="left">VG</th>
<th scope="col" class="left">LV</th>
<th scope="col" class="left">Format</th>
<th scope="col" class="left">Mount Point</th>
<th scope="col" class="left">Size</th>
</tr>
</thead>
<tbody>
<tr>
<td class="left">/dev/sda3</td>
<td class="left">centos</td>
<td class="left">/dev/centos/swap</td>
<td class="left">swap</td>
<td class="left">&#xa0;</td>
<td class="left">7.27G</td>
</tr>

<tr>
<td class="left">&#xa0;</td>
<td class="left">&#xa0;</td>
<td class="left">/dev/centos/home</td>
<td class="left">xfs</td>
<td class="left">/home</td>
<td class="left">180G</td>
</tr>

<tr>
<td class="left">&#xa0;</td>
<td class="left">&#xa0;</td>
<td class="left">/dev/centos/root</td>
<td class="left">xfs</td>
<td class="left">/</td>
<td class="left">50G</td>
</tr>
</tbody>
</table>
</div>
</div>




<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> 増設後のパーティション構成</h2>
<div class="outline-text-2" id="text-5">
<p>
増設したHDDに <code>vg01</code> を増やして、 <code>/home</code> と <code>/var</code> をこちら配置するようにする。
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />

<col  class="left" />

<col  class="left" />

<col  class="left" />

<col  class="left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="left">PV</th>
<th scope="col" class="left">VG</th>
<th scope="col" class="left">LV</th>
<th scope="col" class="left">Format</th>
<th scope="col" class="left">Mount Point</th>
<th scope="col" class="left">Size</th>
</tr>
</thead>
<tbody>
<tr>
<td class="left">/dev/sda3</td>
<td class="left">centos</td>
<td class="left">/dev/centos/swap</td>
<td class="left">swap</td>
<td class="left">&#xa0;</td>
<td class="left">7.27G</td>
</tr>

<tr>
<td class="left">&#xa0;</td>
<td class="left">&#xa0;</td>
<td class="left">/dev/centos/root</td>
<td class="left">xfs</td>
<td class="left">/</td>
<td class="left">230G</td>
</tr>

<tr>
<td class="left">/dev/sdb1</td>
<td class="left">vg01</td>
<td class="left">/dev/vg01/home</td>
<td class="left">xfs</td>
<td class="left">/home</td>
<td class="left">431G</td>
</tr>

<tr>
<td class="left">&#xa0;</td>
<td class="left">&#xa0;</td>
<td class="left">/dev/vg01/var</td>
<td class="left">xfs</td>
<td class="left">/var</td>
<td class="left">500G</td>
</tr>
</tbody>
</table>
</div>
</div>




<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6"><span class="section-number-2">6</span> 増設手順</h2>
<div class="outline-text-2" id="text-6">
</div><div id="outline-container-sec-6-1" class="outline-3">
<h3 id="sec-6-1"><span class="section-number-3">6.1</span> gdiskでパーティションを初期化する</h3>
<div class="outline-text-3" id="text-6-1">
<pre class="example">
$ sudo gdisk /dev/sdb
GPT fdisk (gdisk) version 0.8.6

Partition table scan:
  MBR: not present
  BSD: not present
  APM: not present
  GPT: not present

Creating new GPT entries.

Command (? for help): o        ★GPTパーティションテーブルを新規作成する
This option deletes all partitions and creates a new protective MBR.
Proceed? (Y/N): Y

Command (? for help): n        ★新規パーティションを作成する
Partition number (1-128, default 1): 
First sector (34-1953525134, default = 2048) or {+-}size{KMGTP}: 
Last sector (2048-1953525134, default = 1953525134) or {+-}size{KMGTP}: 
Current type is 'Linux filesystem'
Hex code or GUID (L to show codes, Enter = 8300): 8e00 ★パーティションタイプをLVMにする
Changed type of partition to 'Linux LVM'

Command (? for help): w

Final checks complete. About to write GPT data. THIS WILL OVERWRITE EXISTING
PARTITIONS!!

Do you want to proceed? (Y/N): Y
OK; writing new GUID partition table (GPT) to /dev/sdb.
The operation has completed successfully.
$
</pre>

<p>
結果を確認する
</p>
<pre class="example">
$ sudo gdisk -l /dev/sdb
GPT fdisk (gdisk) version 0.8.6

Partition table scan:
  MBR: protective
  BSD: not present
  APM: not present
  GPT: present

Found valid GPT with protective MBR; using GPT.
Disk /dev/sdb: 1953525168 sectors, 931.5 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): DE117DAF-1D96-4505-89EC-6F1E6BB08E4C
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 1953525134
Partitions will be aligned on 2048-sector boundaries
Total free space is 2014 sectors (1007.0 KiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048      1953525134   931.5 GiB   8E00  Linux LVM
</pre>
</div>
</div>

<div id="outline-container-sec-6-2" class="outline-3">
<h3 id="sec-6-2"><span class="section-number-3">6.2</span> LVMパーティション再構成</h3>
<div class="outline-text-3" id="text-6-2">
<p>
PV <code>/dev/sdb1</code> 作成する
</p>
<pre class="example">
$ sudo pvcreate /dev/sdb1
  Physical volume "/dev/sdb1" successfully created
</pre>

<p>
VG <code>vg01</code> を作成する
</p>
<pre class="example">
$ sudo vgcreate vg01 /dev/sdb1
  Volume group "vg01" successfully created
</pre>

<p>
VG <code>centos</code> の <code>home</code> 論理ボリュームを 一旦 <code>home0</code> にリネームする。
</p>
<pre class="example">
$ sudo lvrename centos home home0
  Renamed "home" to "home0" in volume group "centos"
</pre>

<p>
VG <code>vg01</code> 上で <code>/var</code> 用の <code>var</code> 論理ボリュームを作成する。
</p>
<pre class="example">
$ sudo lvcreate -L 500G vg01 -n var
  Logical volume "var" created
</pre>

<p>
VG <code>vg01</code> 上残りに容量を <code>/home</code> 用の <code>home</code> 論理ボリュームを作成する。
</p>
<pre class="example">
$ sudo lvcreate -l +100%FREE vg01 -n home
  Logical volume "home" created
</pre>

<p>
<code>var</code> 論理ボリュームを <code>xfs</code> タイプファイルシステムでフォーマットする。
</p>
<pre class="example">
$ sudo mkfs.xfs /dev/mapper/vg01-var 
meta-data=/dev/mapper/vg01-var   isize=256    agcount=4, agsize=32768000 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=0
data     =                       bsize=4096   blocks=131072000, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=0
log      =internal log           bsize=4096   blocks=64000, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0

$#+end_example

=home= 論理ボリュームを =xfs= タイプファイルシステムでフォーマットする。
#+begin_example
$ sudo mkfs.xfs /dev/mapper/vg01-home 
meta-data=/dev/mapper/vg01-home  isize=256    agcount=4, agsize=28279296 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=0
data     =                       bsize=4096   blocks=113117184, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=0
log      =internal log           bsize=4096   blocks=55233, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
$
</pre>

<p>
<code>/home</code> 領域データをコピーする。
</p>
<pre class="example">
$ sudo mount /dev/mapper/vg01-home /mnt/
$ sudo cp --archive /home /mnt
$ ls -al /mnt/
合計 4
drwxr-xr-x   3 root root   17 11月 16 22:04 .
drwxr-xr-x. 17 root root 4096 11月 10 21:46 ..
drwxr-xr-x.  3 root root   18  9月 14 23:07 home
$ sudo mv /mnt/home/* /mnt/
$ sudo rm -rf /mnt/home/
$ sudo umount /mnt
</pre>

<p>
<code>/var</code> 領域を使用しているサービスを止めて、データをコピーする。
</p>
<pre class="example">
$ sudo systemctl stop xxxxx.service
$ sudo mount /dev/mapper/vg01-var /mnt/
$ sudo cp --archive /var /mnt
$ sudo mv /mnt/var/* /mnt/
$ sudo rm -rf /mnt/var/
$ sudo umount /mnt
</pre>

<p>
<code>/etc/fstab</code> を適切に変更する。
</p>
<pre class="example">
/dev/mapper/centos-root /                       xfs     defaults        1 1
/dev/mapper/centos-swap swap                    swap    defaults        0 0
/dev/mapper/vg01-home   /home                   xfs     defaults        1 2
/dev/mapper/vg01-var    /var                    xfs     defaults        1 2
.....
</pre>

<p>
旧 <code>/var</code> ディレクトリ名を適当に変更し、システムを再起動する。
</p>
<pre class="example">
$ sudo mv /var /var.0
</pre>

<p>
<code>root</code> 論理ボリュームを拡張する
</p>
<pre class="example">
★home0論理ボリュームの削除
$ sudo lvremove -f centos/home0
  Logical volume "home0" successfully removed

★root論理ボリュームの拡大
$ sudo lvextend -l +100%FREE centos/root
  Extending logical volume root to 230.52 GiB
  Logical volume root successfully resized

★xfsファイルシステムサイズの拡大
$ xfs_growfs /
</pre>
</div>
</div>


<div id="outline-container-sec-6-3" class="outline-3">
<h3 id="sec-6-3"><span class="section-number-3">6.3</span> 増設結果を確認する</h3>
<div class="outline-text-3" id="text-6-3">
<p>
<code>lvmdiskscan</code> の表示
</p>
<pre class="example">
$ sudo lvmdiskscan 
  /dev/centos/swap [       7.27 GiB] 
  /dev/sda1        [     200.00 MiB] 
  /dev/centos/root [     230.52 GiB] 
  /dev/sda2        [     500.00 MiB] 
  /dev/vg01/var    [     500.00 GiB] 
  /dev/sda3        [     237.79 GiB] LVM physical volume
  /dev/vg01/home   [     431.51 GiB] 
  /dev/sdb1        [     931.51 GiB] LVM physical volume
  4 disks
  2 partitions
  0 LVM physical volume whole disks
  2 LVM physical volumes
</pre>

<p>
<code>df -h</code> の表示
</p>
<pre class="example">
$ df -h
ファイルシス            サイズ  使用  残り 使用% マウント位置
/dev/sda1                 200M  9.6M  191M    5% /boot/efi
/dev/sda2                 494M  203M  292M   42% /boot
/dev/mapper/centos-root   231G   16G  215G    7% /
/dev/mapper/vg01-home     432G  379M  431G    1% /home
/dev/mapper/vg01-var      500G   13G  488G    3% /var
.......
</pre>
</div>
</div>
</div>




<div id="outline-container-sec-7" class="outline-2">
<h2 id="sec-7"><span class="section-number-2">7</span> 参考情報</h2>
<div class="outline-text-2" id="text-7">
<ul class="org-ul">
<li><a href="https://wiki.archlinux.org/index.php/Lvm#lvextend">Archlinux Wiki - LVM</a>
</li>
<li><a href="http://kuenishi.hatenadiary.jp/entry/20070325/1174833266">ディスクを加えてXFS on LVMを拡張する</a>
</li>
<li><a href="https://access.redhat.com/documentation/ja-JP/Red_Hat_Enterprise_Linux/6/html/Storage_Administration_Guide/xfsgrow.html">XFS ファイルシステムのサイズの拡大</a>
</li>
</ul>
</div>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[メモ]ApacheでbackendとのKeepAliveをOFFにする]]></title>
    <link href="http://luozengbin.github.io/blog/2014-10-29-%5B%E3%83%A1%E3%83%A2%5Dapache%E3%81%A7backend%E3%81%A8%E3%81%AEkeepalive%E3%82%92off%E3%81%AB%E3%81%99%E3%82%8B.html"/>
    <updated>2014-10-29T00:00:00+09:00</updated>
    <id>http://luozengbin.github.io/blog/[メモ]apacheでbackendとのkeepaliveをoffにする</id>
    <content type="html"><![CDATA[<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. Apache側でKeepAliveを制御する</a></li>
<li><a href="#sec-2">2. APサーバ側にてKeepAliveを制御する</a></li>
<li><a href="#sec-3">3. 参考</a></li>
</ul>
</div>
</div>


<p>
次のような構成でApacheとAPサーバ間のHTTP KeepAliveが有効にすると
</p>


<ol class="org-ol">
<li>LBの振り分けが偏る可能性がある
</li>
<li>LBの無振り分け先の切り替えに影響が生じる可能性がある、詳細は こちらの記事 を参照してください。
</li>
</ol>


<p>
のような不都合があります。
</p>




<pre class="example">
+----------+         +------------+        +-----------+     +-------------+
| Client   +---------&gt; Apache     +--------&gt;   LB      +-----&gt; AP Server   |
+----------+         +------------+        +-----------+     +-------------+
</pre>




<p>
とい言うわけでApacheとAPサーバ間KeepAliveをOFFにする方法を調査した。
</p>




<p>
<!-- more -->
</p>




<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Apache側でKeepAliveを制御する</h2>
<div class="outline-text-2" id="text-1">
<p>
<code>ProxyPass</code> ディレクティブの <code>keepalive</code> パラメータが期待通り動作しないので迷っていた、
しかしドキュメントによると
</p>

<pre class="example">
バックエンドサーバと Apache の間にファイアーウォールがある場合には、 このパラメータを
使ってください。ファイアウォールは往々にして、 非活動状態のコネクションを落とそうとし
ます。 このフラグは OS に指示して、KEEP_ALIVE メッセージを非活動状態の コネクションで
も送るようにします。これによってファイアウォールによってコネクションが 落とされること
を防げます。keepalive を有効にするには、このプロパティを On にしてください。
</pre>

<p>
HTTP KeepAliveに関係しそうに見えたが、実はあんまり関係ないのようです。
TCPレベルでコネクションをファイアウォールによる切断を防ぐためのパラメータです。
</p>

<p>
更に調べると <code>mod_proxy_http</code> モジュールの環境変数にHTTP KeepAliveに関係するものが
出てきた。
</p>

<ul class="org-ul">
<li>force-proxy-request-1.0
プロキシがバックエンドに HTTP/1.0 でリクエストを送るようにし、HTTP/1.1 の機能を無効にします。
</li>

<li>proxy-nokeepalive
プロキシがリクエスト終了後にバックエンドとの接続を切るようにします。
</li>
</ul>

<p>
よし！これだそう。次のように設定したらうまくできた。
</p>
<pre class="example">
&lt;Location /test/&gt;
    ProxyPass http://dummyhost:8080/app1/
    SetEnv proxy-nokeepalive 1
&lt;/Location&gt;
</pre>

<p>
これで、ApacheからAPサーバへのHTTPリクエストヘッダに <code>Connection: close</code> が付与される
ようになりました。 <code>tcpdump</code> でパケットのやり取りを確認すると、ちゃんと毎回クライアン
トのからコネクション切断するためのfinパケットが送信されることを確認しました。
</p>
</div>
</div>




<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> APサーバ側にてKeepAliveを制御する</h2>
<div class="outline-text-2" id="text-2">
<p>
一般的にAPサーバ側でもKeepAliveの設定が可能です。
流れ的に、HTTPレスポンスのHTTPヘッダに <code>Connection: close</code> を付与して返すことで
リクエスト側にコネクション切断する旨を伝える。
</p>

<p>
Tomcat起動時に次のJavaオプションを付けるとHTTP KeepAliveがOFFになります。
</p>
<pre class="example">
-Dorg.apache.coyote.http11.Http11Protocol.MAX_KEEP_ALIVE_REQUESTS=1
</pre>
</div>
</div>




<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> 参考</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li><a href="http://blog.nomadscafe.jp/2011/07/apache.html">今こそ見直すApacheの設定</a>
</li>
</ul>
</div>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[メモ]Zabbix導入記録]]></title>
    <link href="http://luozengbin.github.io/blog/2014-10-16-%5B%E3%83%A1%E3%83%A2%5Dzabbix%E5%B0%8E%E5%85%A5%E8%A8%98%E9%8C%B2.html"/>
    <updated>2014-10-16T00:00:00+09:00</updated>
    <id>http://luozengbin.github.io/blog/[メモ]zabbix導入記録</id>
    <content type="html"><![CDATA[<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. 構成</a></li>
<li><a href="#sec-2">2. インストール</a></li>
<li><a href="#sec-3">3. zabbixの起動</a></li>
<li><a href="#sec-4">4. Zabbix フロントエンドのインストール</a></li>
<li><a href="#sec-5">5. Zabbix エージェントのインストール</a></li>
<li><a href="#sec-6">6. Zabbixのアンインストール</a></li>
<li><a href="#sec-7">7. 参考</a></li>
</ul>
</div>
</div>


<p>
Zabbix2.4、CentOS7用のrpmが見つからなかったので手動ビルドすることにした。
</p>




<p>
<!-- more -->
</p>




<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> 構成</h2>
<div class="outline-text-2" id="text-1">
<pre class="example">
                            +---------------+
                            | Apache 2.4    +---+
                            +---------------+   |         +---------------+
                                                +---------+   Zabbix DB   |
                                                |         +---------------+
              10050       10051                 |         |   PostgreSQL  |
+--------------+            +---------------+   |         +---------------+
| Zabbix Agent +------------+ Zabbix Server +---+
+--------------+            +---------------+
</pre>
</div>
</div>




<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> インストール</h2>
<div class="outline-text-2" id="text-2">
<p>
必要なパッケージのインストール。
</p>
<pre class="example">
$ sudo yum install postgresql-devel
$ sudo yum install libxml2 libxml2-devel
$ sudo yum install net-snmp net-snmp-agent  net-snmp-libs net-snmp-devel
$ sudo yum install libcurl libcurl-devel
$ sudo yum install php-bcmath
</pre>

<p>
ソースコードをダウンロードし、ビルドする。
</p>
<pre class="example">
$ wget http://downloads.sourceforge.net/sourceforge/zabbix/zabbix-2.4.1.tar.gz
$ tar xzvf zabbix-2.4.1.tar.gz
$ cd zabbix-2.4.1/
$ ./configure --enable-server --enable-agent  --with-postgresql --with-net-snmp --with-libcurl --with-libxml2 --enable-java --sysconfdir=/etc/zabbix
$ sudo make install
</pre>

<p>
Zabbix設定ファイル、DB初期化用SQLを格納用のディレクトリの作成とファイルのコピー。
</p>
<pre class="example">
$ sudo mkdir -p /etc/zabbix/database/postgresql
$ sudo mkdir -p /etc/zabbix/database/postgresql/upgrade/2.0

$ sudo cp -v ./database/postgresql/*.sql /etc/zabbix/database/postgresql
$ sudo cp -v ./upgrades/dbpatches/2.0/postgresql/patch.sql /etc/zabbix/database/postgresql/upgrade/2.0

$ sudo chmod 0444 /etc/zabbix/database/postgresql/*.sql
$ sudo chmod 0444 /etc/zabbix/database/postgresql/upgrade/2.0/*.sql
</pre>

<p>
Zabbixログ格納用ディレクトリの作成。
</p>
<pre class="example">
$ sudo mkdir -m 0750 /var/log/zabbix
</pre>

<p>
Zabbixプロセス実行ユーザの登録、ディレクトリ権限の付与。
</p>
<pre class="example">
$ sudo groupadd -r zabbix
$ sudo useradd -r -g zabbix -d /dev/null zabbix -s /sbin/nologin
$ sudo chown -R zabbix:zabbix /var/log/zabbix
$ sudo chown -R zabbix:zabbix /etc/zabbix
$ sudo chown -R zabbix:zabbix /usr/local/share/zabbix
</pre>

<p>
Zabbixサーバ設定ファイルにPIDの格納場所を指定する。
</p>
<pre class="example">
$ sudo chmod 0640 /etc/zabbix/zabbix_server.conf
$ sudo sed -i 's:# PidFile=.*:PidFile=/run/zabbix/zabbix_server.pid:' /etc/zabbix/zabbix_server.conf
</pre>

<p>
Zabbixサーバ設定ファイルにログの格納場所を指定する
</p>
<pre class="example">
$ sudo sed -i 's:^LogFile=.*:LogFile=/var/log/zabbix/zabbix_server.log:' /etc/zabbix/zabbix_server.conf
</pre>

<p>
監視結果データ及び監視項目設定データを格納するためのDBを作成する。
</p>
<pre class="example">
# su - postgresql
-bash-4.2$ createuser --pwprompt zabbix      ★接続ユーザの作成
-bash-4.2$ createdb --owner=zabbix zabbix    ★データベース作成
</pre>

<p>
作成したデータベースにスキーマを初期化する。
</p>
<pre class="example">
$ cd /etc/zabbix/database/postgresql
$ psql -U zabbix zabbix &lt; schema.sql
$ psql -U zabbix zabbix &lt; images.sql
$ psql -U zabbix zabbix &lt; data.sql
</pre>

<p>
Zabbixサーバ設定ファイルにDB接続情報を変更する。
</p>
<pre class="example">
DBHost=localhost
DBName=zabbix
DBUser=zabbix
DBPassword=******
DBPort=5432
</pre>

<p>
PIDファイルの親ディレクトリをtmp領域に作成するため、 <code>systemd-tmpfiles</code> 機能でOS起
動時に予め作成するようにする。
</p>

<p>
<code>/usr/lib/tmpfiles.d/zabbix-server.conf</code>
</p>
<pre class="example">
d /run/zabbix 0755 zabbix zabbix -
</pre>

<p>
<code>systemd-tmpfiles</code> 手動実行で、ディレクトリを作成する。OS再起動する場合、この手順は不
要です。
</p>
<pre class="example">
$ sudo systemd-tmpfiles --create /usr/lib/tmpfiles.d/zabbix-server.conf
</pre>

<p>
<code>systemd</code> から起動停止できるように <code>zabbix-server.service</code> を作成する。
</p>

<p>
<code>/usr/lib/systemd/system/zabbix-server.service</code>
</p>
<pre class="example">
[Unit]
Description=Zabbix server
After=syslog.target network.target postgresql.service

[Service]
Type=forking
User=root
ExecStart=/usr/local/sbin/zabbix_server
PIDFile=/run/zabbix/zabbix_server.pid

[Install]
WantedBy=multi-user.target
</pre>
</div>
</div>




<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> zabbixの起動</h2>
<div class="outline-text-2" id="text-3">
<p>
<code>systemctl</code> コマンドで起動する。
</p>
<pre class="example">
$ sudo systemctl enable zabbix-server.service
$ sudo systemctl start zabbix-server.service
</pre>

<p>
ポート確認
</p>
<pre class="example">
$ sudo netstat -nutpl | grep zabbix
tcp        0      0 0.0.0.0:10051           0.0.0.0:*               LISTEN      23765/zabbix_server
</pre>

<p>
ログ確認
</p>
<pre class="example">
# cat zabbix_server.log
 23765:20141016:231838.117 Starting Zabbix Server. Zabbix 2.4.1 (revision 49643).
 23765:20141016:231838.118 ****** Enabled features ******
 23765:20141016:231838.118 SNMP monitoring:           YES
 23765:20141016:231838.118 IPMI monitoring:            NO
 23765:20141016:231838.118 WEB monitoring:            YES
 23765:20141016:231838.118 VMware monitoring:         YES
 23765:20141016:231838.118 Jabber notifications:       NO
 23765:20141016:231838.118 Ez Texting notifications:  YES
 23765:20141016:231838.118 ODBC:                       NO
 23765:20141016:231838.118 SSH2 support:               NO
 23765:20141016:231838.118 IPv6 support:               NO
 23765:20141016:231838.118 ******************************
 23765:20141016:231838.118 using configuration file: /etc/zabbix/zabbix_server.conf
 23765:20141016:231838.157 current database version (mandatory/optional): 02040000/02040000
 23765:20141016:231838.157 required mandatory version: 02040000
 23765:20141016:231838.190 server #0 started [main process]
 23775:20141016:231838.191 server #1 started [configuration syncer #1]
 23776:20141016:231838.191 server #2 started [db watchdog #1]
 23777:20141016:231838.191 server #3 started [poller #1]
 23781:20141016:231838.193 server #5 started [poller #3]
 23783:20141016:231838.195 server #7 started [poller #5]
 23782:20141016:231838.201 server #6 started [poller #4]
 23789:20141016:231838.201 server #12 started [trapper #4]
 23786:20141016:231838.202 server #9 started [trapper #1]
 23788:20141016:231838.203 server #11 started [trapper #3]
 23790:20141016:231838.203 server #13 started [trapper #5]
 23794:20141016:231838.204 server #17 started [timer #1]
 23791:20141016:231838.204 server #14 started [icmp pinger #1]
 23787:20141016:231838.204 server #10 started [trapper #2]
 23792:20141016:231838.204 server #15 started [alerter #1]
 23784:20141016:231838.207 server #8 started [unreachable poller #1]
 23795:20141016:231838.208 server #18 started [http poller #1]
 23799:20141016:231838.208 server #21 started [history syncer #2]
 23806:20141016:231838.209 server #23 started [history syncer #4]
 23809:20141016:231838.209 server #26 started [self-monitoring #1]
 23780:20141016:231838.210 server #4 started [poller #2]
 23801:20141016:231838.211 server #22 started [history syncer #3]
 23793:20141016:231838.211 server #16 started [housekeeper #1]
 23797:20141016:231838.211 server #20 started [history syncer #1]
 23807:20141016:231838.214 server #24 started [escalator #1]
 23808:20141016:231838.215 server #25 started [proxy poller #1]
 23796:20141016:231838.309 server #19 started [discoverer #1]
</pre>
</div>
</div>




<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> Zabbix フロントエンドのインストール</h2>
<div class="outline-text-2" id="text-4">
<p>
phpコンテンツ格納するディレクトリの作成とコンテンツ実体の格納。
</p>
<pre class="example">
$ sudo mkdir -p /var/www/zabbix
$ sudo cp -r frontends/php/* /var/www/zabbix
$ sudo chown -R apache:apache /var/www/zabbix
$ sudo chmod -R u=rwX,g=rX,o= /var/www/zabbix
</pre>

<p>
<code>/etc/php.ini</code> にてphp実行時パラメータを変更する。
</p>
<pre class="example">
max_execution_time = 300     ★変更
max_input_time = 300         ★変更
post_max_size = 16M          ★変更
memory_limit = 128M
upload_max_filesize = 2M
session.auto_start = 0
date.timezone = "Asia/Tokyo" ★変更
</pre>

<p>
フラフの日本語表示対応
</p>
<pre class="example">
$ sudo yum install ipa-gothic-fonts ipa-pgothic-fonts vlgothic-fonts vlgothic-p-fonts
$ sudo -u apache cp /usr/share/fonts/ipa-gothic/ipag.ttf /var/www/zabbix/fonts/
</pre>

<p>
<code>/var/www/zabbix/include/defines.inc.php</code>
</p>
<pre class="example">
変更前
define('ZBX_GRAPH_FONT_NAME',           'DejaVuSans'); // font file name

変更後
define('ZBX_GRAPH_FONT_NAME',           'ipag'); // font file name
</pre>

<p>
Apache設定内容 <code>/etc/httpd/conf.d/httpd-zabbix.conf</code>
</p>
<pre class="example">
Alias /zabbix /var/www/zabbix
&lt;Location /zabbix&gt;
    # Apache 2.4
    Require local
    #Require host example.com
&lt;/Location&gt;
</pre>

<p>
<code>/etc/httpd/conf/httpd.conf</code>
</p>
<pre class="example">
IncludeOptional conf.d/httpd-zabbix.conf
</pre>

<p>
画面を起動する。
</p>

<video controls>
   <source src="video/2014-10-17_zabbix_install_01.mp4">
</video>

<p>
ウィザードで生成しれたファイルの内容 <code>/var/www/zabbix/conf/zabbix.conf.php</code>
</p>
<pre class="example">
&lt;?php
// Zabbix GUI configuration file
global $DB;

$DB['TYPE']     = 'POSTGRESQL';
$DB['SERVER']   = 'localhost';
$DB['PORT']     = '0';
$DB['DATABASE'] = 'zabbix';
$DB['USER']     = 'zabbix';
$DB['PASSWORD'] = '**********';

// SCHEMA is relevant only for IBM_DB2 database
$DB['SCHEMA'] = '';

$ZBX_SERVER      = 'localhost';
$ZBX_SERVER_PORT = '10051';
$ZBX_SERVER_NAME = '';

$IMAGE_FORMAT_DEFAULT = IMAGE_FORMAT_PNG;
?&gt;
</pre>
</div>
</div>




<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> Zabbix エージェントのインストール</h2>
<div class="outline-text-2" id="text-5">
<p>
Zabbix AgentプロセスのPID格納用ディレクトリの初期化。
<code>/usr/lib/tmpfiles.d/zabbix-agentd.conf</code>
</p>
<pre class="example">
$ sudo touch /usr/lib/tmpfiles.d/zabbix-agentd.conf
$ sudo nano /usr/lib/tmpfiles.d/zabbix-agentd.conf
d /run/zabbix 0755 zabbix zabbix -
</pre>

<pre class="example">
$ sudo systemd-tmpfiles --create /usr/lib/tmpfiles.d/zabbix-agentd.conf
</pre>

<p>
Zabbix Agentサービス起動・停止用のファイル <code>/usr/lib/systemd/system/zabbix-agentd.service</code>
</p>
<pre class="example">
[Unit]
Description=Zabbix agent daemon
After=network.target

[Service]
Type=forking
User=root
ExecStart=/usr/local/sbin/zabbix_agentd
PIDFile=/run/zabbix/zabbix_agentd.pid

[Install]
WantedBy=multi-user.target
</pre>

<p>
Zabbix Agent設定ファイルに、PID及びログ出力先を変更する。
</p>
<pre class="example">
$ sudo -u zabbix sed -i 's:# PidFile=.*:PidFile=/run/zabbix/zabbix_agentd.pid:' /etc/zabbix/zabbix_agentd.conf
$ sudo -u zabbix sed -i 's:^LogFile=.*:LogFile=/var/log/zabbix/zabbix_agentd.log:' /etc/zabbix/zabbix_agentd.conf
</pre>

<p>
Zabbix Agent設定ファイルに、Zabbix Serverの情報と監視ホスト名を指定する。
</p>
<pre class="example">
Server=127.0.0.1
ServerActive=127.0.0.1
Hostname=testhost
</pre>

<p>
ポートの確認
</p>
<pre class="example">
$ sudo netstat -nutpl | grep zabbix
tcp        0      0 0.0.0.0:10050           0.0.0.0:*               LISTEN      17764/zabbix_agentd
</pre>
</div>
</div>




<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6"><span class="section-number-2">6</span> Zabbixのアンインストール</h2>
<div class="outline-text-2" id="text-6">
<pre class="example">
$ sudo userdel zabbix
</pre>

<p>
※未完成
</p>
</div>
</div>




<div id="outline-container-sec-7" class="outline-2">
<h2 id="sec-7"><span class="section-number-2">7</span> 参考</h2>
<div class="outline-text-2" id="text-7">
<ul class="org-ul">
<li><a href="https://www.zabbix.com/documentation/2.2/jp/start">Zabbix documentation in Japanese</a>
</li>
<li><a href="http://www.sraoss.co.jp/technology/zabbix/introduction/01-firststep.php">第 1 回 Zabbix を動かしてみよう</a>
</li>
<li><a href="http://tech-sketch.jp/2011/11/osszabbix1.html">OSS統合監視ツール「Zabbix」を利用して大規模環境監視(1)</a>
</li>
</ul>
</div>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[レシピ]Kerbroseパスワード変更ためのPAM設定]]></title>
    <link href="http://luozengbin.github.io/blog/2014-08-16-%5B%E3%83%AC%E3%82%B7%E3%83%94%5Dkerbrose%E3%83%91%E3%82%B9%E3%83%AF%E3%83%BC%E3%83%89%E5%A4%89%E6%9B%B4%E3%81%9F%E3%82%81%E3%81%AEpam%E8%A8%AD%E5%AE%9A.html"/>
    <updated>2014-08-16T00:00:00+09:00</updated>
    <id>http://luozengbin.github.io/blog/[レシピ]kerbroseパスワード変更ためのpam設定</id>
    <content type="html"><![CDATA[<p>
前の記事で <code>pam_krb5</code> モジュールでKerbrose認証を実現しました。ここで <code>passwd</code> コマン
ドラインでKDCに登録されたプリンシバル鍵のパスワードを変更する方法を紹介します。
</p>




<p>
<!-- more -->
</p>




<p>
<code>passwd</code> コマンド実行時に裏で動いているのはPAMモジュールですので、
<code>/etc/pam.d./passwd</code> に <code>pam_kbr5</code> モジュールを適用するようにすれば、パスワード変更時
に自動的にKDCのデータベースに反映されます。
</p>




<p>
<code>/etc/pam.d./passwd</code>
</p>


<pre class="example">
#%PAM-1.0
password        requisite       pam_cracklib.so retry=3 difok=1 minlen=8 dcredit=-1
password        sufficient      pam_unix.so sha512 shadow nullok use_authtok
password        sufficient      pam_krb5.so   ★ここです
password        required        pam_deny.so
</pre>




<p>
パスワード変更を実行してみましょう。
</p>


<pre class="example">
[kbr_u01@mimi ~]$ passwd
Kerberos 5 パスワード:                     ★現在のパスワードが聞かれる
新しいパスワード:
新しいパスワードを再入力してください:
passwd: パスワードは正しく更新されました
[kbr_u01@mimi ~]$
</pre>




<p>
パスワード変更時のシスログ
</p>


<pre class="example">
Aug 16 19:01:38 mimi passwd[15359]: pam_unix(passwd:chauthtok): user "kbr_u01" does not exist in /etc/passwd
Aug 16 19:01:38 mimi passwd[15359]: pam_krb5[15359]: password changed for kbr_u01@JIZAI-DOMAIN.JP
Aug 16 19:01:38 mimi passwd[15359]: pam_krb5[15359]: TGT verified using key for 'host/mimi.jizai-domain.jp@JIZAI-DOMAIN.JP'
</pre>




<p>
KDCサーバ側のログ
</p>


<pre class="example">
2014-08-16T19:34:36+09:00 pipi local5 info krb5kdc[28554]:  AS_REQ (6 etypes {18 17 16 23 25 26}) 192.168.100.10: ISSUE: authtime 1408185276, etypes {rep=18 tkt=18 ses=18}, kbr_u01@JIZAI-DOMAIN.JP for kadmin/changepw@JIZAI-DOMAIN.JP
2014-08-16T19:34:36+09:00 pipi local5 info krb5kdc[28554]:  AS_REQ (6 etypes {18 17 16 23 25 26}) 192.168.100.10: ISSUE: authtime 1408185276, etypes {rep=18 tkt=18 ses=18}, kbr_u01@JIZAI-DOMAIN.JP for kadmin/changepw@JIZAI-DOMAIN.JP

2014-08-16T19:34:59+09:00 pipi local5 info krb5kdc[28554]:  AS_REQ (6 etypes {18 17 16 23 25 26}) 192.168.100.10: ISSUE: authtime 1408185299, etypes {rep=18 tkt=18 ses=18}, kbr_u01@JIZAI-DOMAIN.JP for krbtgt/JIZAI-DOMAIN.JP@JIZAI-DOMAIN.JP
2014-08-16T19:34:59+09:00 pipi local5 info krb5kdc[28554]:  AS_REQ (6 etypes {18 17 16 23 25 26}) 192.168.100.10: ISSUE: authtime 1408185299, etypes {rep=18 tkt=18 ses=18}, kbr_u01@JIZAI-DOMAIN.JP for krbtgt/JIZAI-DOMAIN.JP@JIZAI-DOMAIN.JP
2014-08-16T19:34:59+09:00 pipi local5 info krb5kdc[28554]:  TGS_REQ (6 etypes {18 17 16 23 25 26}) 192.168.100.10: ISSUE: authtime 1408185299, etypes {rep=18 tkt=18 ses=18}, kbr_u01@JIZAI-DOMAIN.JP for host/mimi.jizai-domain.jp@JIZAI-DOMAIN.JP
2014-08-16T19:34:59+09:00 pipi local5 info krb5kdc[28554]:  TGS_REQ (6 etypes {18 17 16 23 25 26}) 192.168.100.10: ISSUE: authtime 1408185299, etypes {rep=18 tkt=18 ses=18}, kbr_u01@JIZAI-DOMAIN.JP for host/mimi.jizai-domain.jp@JIZAI-DOMAIN.JP
</pre>

]]></content>
  </entry>
  
</feed>
